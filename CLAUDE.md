# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ðŸŽ¯ Project Overview

**Samba-Orion** is an AI chatbot platform built entirely on **Vercel AI SDK** as the foundational AI framework, with Next.js 15 and TypeScript. This project is a branded fork of the open-source "better-chatbot" project, strategically rebranded to maintain upstream compatibility while providing a unique user experience.

### ðŸŽ¨ Dual Branding Strategy
- **User-Facing Elements:** "Samba-Orion" branding (UI, page titles, app names, user-visible text)
- **Backend/Infrastructure:** "better-chatbot" structure preserved (file paths, git history, documentation references)
- **Upstream Compatibility:** Enables easy merging of updates from the open-source better-chatbot project

**Core Features:** Unified interface to multiple LLM providers (OpenAI, Anthropic, Google, xAI, Ollama, OpenRouter) through Vercel AI SDK abstractions, enhanced with MCP protocol support, custom agents, visual workflows, **multi-grid Canvas for data visualization and dashboard creation**, and comprehensive observability.

**Foundational Architecture:**
- **AI Framework:** Vercel AI SDK (foundational - all AI operations built on this)
- **Framework:** Next.js 15 with App Router
- **Language:** TypeScript
- **Observability:** Langfuse SDK v4 with OpenTelemetry
- **Database:** PostgreSQL with Drizzle ORM
- **Authentication:** Better-Auth
- **UI:** React with Tailwind CSS, Radix UI, Framer Motion
- **Testing:** Vitest (unit), Playwright (e2e)
- **Linting/Formatting:** Biome

## ðŸ› ï¸ Development Commands

### Essential Commands
```bash
# Development server with Turbopack
pnpm dev

# Production build and start (recommended for most development)
pnpm build:local && pnpm start

# Testing
pnpm test                    # Run unit tests with Vitest
pnpm test:watch             # Watch mode for unit tests
pnpm test:e2e               # End-to-end tests with Playwright
pnpm test:e2e:ui           # Playwright UI mode

# Code quality
pnpm lint                   # ESLint + Biome linting
pnpm lint:fix              # Fix linting issues
pnpm format                # Format code with Biome
pnpm check-types           # TypeScript type checking
pnpm check                 # Full check: lint + types + tests

# Database operations
pnpm db:generate           # Generate Drizzle migrations
pnpm db:push              # Push schema to database
pnpm db:migrate           # Run migrations
pnpm db:studio            # Open Drizzle Studio
pnpm db:reset             # Drop and recreate database
```

### Docker Commands
```bash
# Local PostgreSQL instance
pnpm docker:pg

# Redis instance
pnpm docker:redis

# Full Docker Compose stack
pnpm docker-compose:up
pnpm docker-compose:down
pnpm docker-compose:logs
```

### Utility Scripts
```bash
# Initialize environment files
pnpm initial:env

# OpenAI-compatible provider management
pnpm openai-compatiable:init
pnpm openai-compatiable:parse

# Clean build artifacts
pnpm clean
```

## ðŸ—ï¸ Architecture Overview

### Core System Architecture

**Vercel AI SDK Foundation:**
- **All AI operations** built on `streamText`, `generateText`, and tool abstractions
- **Unified Provider Interface:** OpenAI, Anthropic, Google, xAI, Ollama, OpenRouter through SDK
- **Streaming-First:** Real-time responses with `experimental_telemetry` for observability
- **Tool Integration:** MCP, Workflow, and App tools conform to Vercel AI SDK tool interface
- **Observability:** Automatic tracing through Langfuse SDK v4 integration

**Chat System Flow (Vercel AI SDK-Centric):**
1. **Request:** `/api/chat/route.ts` handles chat requests with observability
2. **Tool Loading:** MCP, workflow, and app tools loaded as Vercel AI SDK tools
3. **Model Provider:** `customModelProvider.getModel()` returns Vercel AI SDK models
4. **AI Processing:** `streamText()` with `experimental_telemetry` for comprehensive tracing
5. **Tool Execution:** Automatic tool calls through Vercel AI SDK abstractions
6. **Canvas Integration:** Chart tools automatically stream to Canvas workspace using progressive building
7. **Observability:** Real-time trace capture via Langfuse integration
8. **Response:** Streaming UI components handle Vercel AI SDK message streams
9. **Database:** Messages and metadata stored via `chatRepository`

**Observability Architecture (Langfuse SDK v4):**
- **Instrumentation:** `instrumentation.ts` with `NodeTracerProvider` and `LangfuseSpanProcessor`
- **Tracing:** Automatic via Vercel AI SDK `experimental_telemetry`
- **Scope:** Complete conversations, tool executions, streaming responses, costs
- **Integration:** Built-in compatibility with Vercel AI SDK patterns

**MCP (Model Context Protocol) Integration:**
- Central to the application's extensibility
- Located in `src/lib/ai/mcp/`
- `mcpClientsManager` manages all MCP server connections
- **Vercel AI SDK Integration:** MCP tools converted to Vercel AI SDK tool interface
- Supports both file-based and database-based configurations
- Tools dynamically loaded and bound through Vercel AI SDK abstractions

**Database Layer (Drizzle ORM):**
- Schema: `src/lib/db/pg/schema.pg.ts`
- Repositories: `src/lib/db/pg/repositories/`
- Migrations: `src/lib/db/migrations/pg/`

### Key Components Architecture

**Authentication (Better-Auth):**
- Configuration: `src/lib/auth/config.ts`
- Server functions: `src/lib/auth/server.ts`
- Client hooks: `src/lib/auth/client.ts`
- Supports OAuth (Google, GitHub, Microsoft) and email/password

**Multi-Provider Support (Vercel AI SDK):**
- **Unified Interface:** All providers accessed through Vercel AI SDK abstractions in `src/lib/ai/models.ts`
- **Provider Coverage:** OpenAI, Anthropic, Google, xAI, Ollama, OpenRouter via `@ai-sdk/*` packages
- **Dynamic Models:** Static models + dynamic OpenAI-compatible providers
- **Consistent API:** All providers use `streamText`/`generateText` with identical interfaces
- **Tool Call Support:** Universal tool calling across all supported providers
- **Observability:** Automatic tracing via `experimental_telemetry` across all providers

**Agent System:**
- Custom AI agents with specific instructions and tool access
- Database schema: `AgentSchema` in schema.pg.ts
- UI: `src/components/agent/`

**Workflow Engine (Vercel AI SDK Integration):**
- Visual workflow builder using XYFlow
- Located in `src/lib/ai/workflow/`
- **Vercel AI SDK Integration:** Workflows converted to Vercel AI SDK tool interface
- **Tool Abstraction:** Workflows become callable tools through `createTool()`
- **Streaming Support:** Workflow execution integrated with Vercel AI SDK streaming
- **Node Types:** LLM nodes (using `generateText`) and Tool nodes (MCP/App tools)
- **Observability:** Workflow execution automatically traced via `experimental_telemetry`

**Canvas System (Multi-Grid Data Visualization):**
- Multi-grid dashboard layout for progressive chart building
- Located in `src/components/canvas-panel.tsx` and `src/components/canvas/`
- **Vercel AI SDK Integration:** Chart tools use native `async function*` streaming patterns
- **Progressive Building:** Charts appear in Canvas as AI creates them using `yield` statements
- **Responsive Design:** Charts scale smoothly with Canvas panel resizing
- **Smart Naming:** Canvas names generated automatically based on chart content analysis
- **Integration:** ResizablePanelGroup allows Canvas alongside chat interface

## ðŸ” Observability Architecture

**Langfuse SDK v4 Integration:**
- **Framework:** Built on OpenTelemetry with Langfuse SDK v4 packages
- **Packages:** `@langfuse/otel`, `@langfuse/tracing`, `@opentelemetry/sdk-trace-node`
- **Pattern:** `NodeTracerProvider` with `LangfuseSpanProcessor` (not `@vercel/otel` due to compatibility)
- **Instrumentation:** `instrumentation.ts` automatically loaded by Next.js

**Vercel AI SDK Observability:**
- **Automatic Tracing:** All `streamText`/`generateText` calls automatically traced
- **Tool Execution:** Individual tool calls captured as nested spans
- **Streaming Support:** Real-time response tracing without blocking
- **Multi-Provider:** Consistent tracing across all AI providers
- **Configuration:** `experimental_telemetry` enables comprehensive observability

**Trace Structure:**
```
handle-chat-message (observe wrapper)
â”œâ”€â”€ better-chatbot-conversation (trace)
â”‚   â”œâ”€â”€ ai.streamText (automatic Vercel AI SDK span)
â”‚   â”œâ”€â”€ tool.execution (automatic for each tool call)
â”‚   â”‚   â”œâ”€â”€ mcp.toolCall (MCP server interactions)
â”‚   â”‚   â”œâ”€â”€ workflow.execute (workflow node execution)
â”‚   â”‚   â””â”€â”€ app.defaultTool (built-in tool execution)
â”‚   â”œâ”€â”€ provider.generateText (OpenAI/Anthropic/Google/etc.)
â”‚   â””â”€â”€ streaming.response (real-time response chunks)
â””â”€â”€ metadata: userId, sessionId, costs, tokens, performance
```

**Captured Metrics:**
- **User Analytics:** Session tracking, user journeys, engagement patterns
- **AI Performance:** Token usage, costs, latency per provider and model
- **Tool Analytics:** MCP server health, tool execution success rates, workflow performance
- **System Health:** Error rates, response times, resource utilization
- **Business Intelligence:** Feature usage, agent effectiveness, cost optimization

**Production Benefits:**
- **Cost Optimization:** Real-time token and cost tracking across all providers
- **Performance Monitoring:** Identify bottlenecks in AI processing and tool execution
- **User Experience:** Track conversation quality and user satisfaction patterns
- **Debugging:** Complete trace visibility for troubleshooting complex AI interactions
- **A/B Testing:** Compare model performance and feature effectiveness

### Directory Structure

```
better-chatbot/
â”œâ”€â”€ instrumentation.ts      # ðŸ” Langfuse SDK v4 observability setup (critical)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/               # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ (auth)/        # Authentication pages
â”‚   â”‚   â”œâ”€â”€ (chat)/        # Main chat interface
â”‚   â”‚   â””â”€â”€ api/           # API routes (Vercel AI SDK streaming endpoints)
â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ agent/         # Agent management UI
â”‚   â”‚   â”œâ”€â”€ canvas/        # Canvas workspace components
â”‚   â”‚   â”œâ”€â”€ layouts/       # App layout components
â”‚   â”‚   â”œâ”€â”€ tool-invocation/ # Tool result components (Vercel AI SDK tool results)
â”‚   â”‚   â””â”€â”€ ui/            # Reusable UI components
â”‚   â””â”€â”€ lib/               # Core business logic
â”‚       â”œâ”€â”€ ai/            # AI-related functionality (Vercel AI SDK-centric)
â”‚       â”‚   â”œâ”€â”€ mcp/       # MCP protocol â†’ Vercel AI SDK tool conversion
â”‚       â”‚   â”œâ”€â”€ tools/     # Built-in tools (web search, code execution, chart creation)
â”‚       â”‚   â”œâ”€â”€ workflow/  # Workflow engine â†’ Vercel AI SDK tool integration
â”‚       â”‚   â””â”€â”€ models.ts  # Vercel AI SDK provider configurations
â”‚       â”œâ”€â”€ auth/          # Authentication logic
â”‚       â”œâ”€â”€ db/            # Database layer
â”‚       â””â”€â”€ cache/         # Caching (Redis/memory)
â””â”€â”€ docs/                  # Documentation
    â”œâ”€â”€ langfuse-vercel-ai-sdk.md # Observability integration guide
    â””â”€â”€ tips-guides/       # Setup and configuration guides
```

## ðŸ”§ Development Patterns

### Database Patterns
- **Repositories:** Use repository pattern in `src/lib/db/repository.ts`
- **Migrations:** Generate with `pnpm db:generate`, run with `pnpm db:migrate`
- **Schema Changes:** Update `schema.pg.ts` then generate migrations

### Component Patterns
- **Server Components:** Default for data fetching
- **Client Components:** Mark with `"use client"` for interactivity
- **UI Components:** Use Radix UI primitives in `src/components/ui/`
- **Styling:** Tailwind CSS with custom design system

### Vercel AI SDK Patterns
- **AI Operations:** All AI calls use `streamText`/`generateText` from Vercel AI SDK
- **Tool Integration:** Convert all tools (MCP, Workflow, App) to Vercel AI SDK tool interface
- **Streaming:** Leverage `createUIMessageStream` and `experimental_telemetry` for observability
- **Canvas Integration:** Chart tools use native `async function*` streaming with `yield` statements
- **Progressive Building:** Canvas artifacts built progressively as AI streams tool execution
- **Provider Management:** Use `customModelProvider.getModel()` for unified model access
- **Observability:** Enable `experimental_telemetry` on all AI operations for comprehensive tracing

### API Route Patterns (Vercel AI SDK-Centric)
- **Authentication:** Use `getSession()` from `auth/server`
- **Error Handling:** Use `ts-safe` for safe error handling
- **Validation:** Zod schemas in `app-types/` directory
- **AI Streaming:** Use Vercel AI SDK's `streamText` with `experimental_telemetry`
- **Tool Execution:** Leverage Vercel AI SDK tool abstractions for all tool types
- **Observability:** Automatic tracing via Langfuse integration with zero additional code

### MCP Development (Vercel AI SDK Integration)
- **Tool Conversion:** Convert MCP tools to Vercel AI SDK tool interface in `shared.chat.ts`
- **MCP Servers:** Configure in database or JSON files
- **Tool Binding:** Dynamic loading as Vercel AI SDK tools in chat routes
- **Observability:** MCP tool calls automatically traced via `experimental_telemetry`
- **Testing:** Use `src/app/(chat)/mcp/test/[id]/page.tsx`

## ðŸ§ª Testing

### Unit Tests (Vitest)
- Files: `*.test.ts` alongside source files
- Config: Uses `vite-tsconfig-paths` for path resolution
- Run: `pnpm test` or `pnpm test:watch`

### E2E Tests (Playwright)
- Directory: `tests/`
- Config: `playwright.config.ts`
- Setup: Authentication states in `tests/lifecycle/`
- Run: `pnpm test:e2e` or `pnpm test:e2e:ui`

### Test Patterns
- **Database Tests:** Use test database with cleanup
- **MCP Tests:** Mock MCP server responses
- **Authentication Tests:** Use setup projects for auth state
- **Agent Tests:** Test agent visibility and permissions

## ðŸ” Environment Setup

Required variables (auto-generated `.env`):
```bash
# At least one LLM provider API key
OPENAI_API_KEY=****
ANTHROPIC_API_KEY=****
GOOGLE_GENERATIVE_AI_API_KEY=****

# Database
POSTGRES_URL=postgres://user:pass@localhost:5432/db

# Authentication
BETTER_AUTH_SECRET=****

# Optional features
EXA_API_KEY=****           # Web search
FILE_BASED_MCP_CONFIG=false # MCP config storage
```

## ðŸŽ¨ Code Style

- **Formatting:** Biome with 2-space indentation, 80-character line width
- **Imports:** Auto-organized with Biome
- **TypeScript:** Strict mode enabled
- **File Naming:** kebab-case for files, PascalCase for components
- **Comments:** Use intelligently for learning purposes (per user config)

## ðŸ“‹ GitHub Workflow Conventions

### Pull Request Title Format (REQUIRED)
All PR titles MUST follow Conventional Commit format enforced by automated checks:

**Format:** `type(scope): description`

**Supported Types:**
- `feat` - new features
- `fix` - bug fixes
- `chore` - maintenance tasks
- `docs` - documentation changes
- `style` - formatting changes
- `refactor` - code refactoring
- `test` - test additions/changes
- `perf` - performance improvements
- `build` - build system changes
- `ci` - CI configuration changes
- `revert` - reverting changes

**Examples:**
- âœ… `feat: add user authentication system`
- âœ… `fix: correct database connection timeout`
- âœ… `chore: update dependencies`
- âœ… `feat(auth): add OAuth integration`
- âŒ `Add new feature` (missing type)
- âŒ `Fix bug` (too generic)

### Automated Quality Checks
PRs must pass these automated workflows:
- **Lint Check:** Code formatting with Biome (`pnpm lint`)
- **Type Check:** TypeScript validation (`pnpm check-types`)
- **Unit Tests:** All tests must pass (`pnpm test`)
- **PR Title:** Conventional commit format validation

### Additional CI/CD Workflows
- **E2E Tests:** Full end-to-end testing with Playwright on main/develop branches
- **Container Publishing:** Docker images published to GitHub Container Registry on releases
- **Release Management:** Automated with release-please for changelog generation

## ðŸš€ Production Deployment

### Build Process
```bash
pnpm build:local          # Local build (no HTTPS)
pnpm build               # Production build with HTTPS
```

### Database Setup
1. Create PostgreSQL database
2. Set `POSTGRES_URL` in environment
3. Run `pnpm db:push` to create tables
4. Optional: Run `pnpm db:migrate` for migrations

### Docker Deployment
- Dockerfile: `docker/Dockerfile`
- Compose: `docker/compose.yml`
- Command: `pnpm docker-compose:up`

### Environment-Specific Notes
- **Vercel:** Use built-in PostgreSQL integration
- **Self-hosted:** Configure PostgreSQL and Redis
- **Development:** Use `pnpm docker:pg` for local database

## ðŸ” Debugging Tips

### Common Issues
- **MCP Servers:** Check connection status in `/mcp` page
- **Database:** Use `pnpm db:studio` to inspect data
- **Authentication:** Check session in dev tools
- **Tool Execution:** Monitor logs in chat interface

### Development Tools
- **Database Studio:** `pnpm db:studio`
- **Type Checking:** `pnpm check-types`
- **Playwright Debug:** `pnpm test:e2e:ui`
- **Hot Reload:** `pnpm dev` with Turbopack

## ðŸ“š Key Files for Understanding

### Core Architecture Files
- `instrumentation.ts` - **ðŸ” Langfuse observability setup (CRITICAL)** - NodeTracerProvider with LangfuseSpanProcessor
- `src/app/api/chat/route.ts` - **Main chat API** - Vercel AI SDK streaming with experimental_telemetry
- `src/lib/ai/models.ts` - **Vercel AI SDK provider configuration** - Unified model interface
- `src/components/chat-bot.tsx` - **Main chat interface** - Handles Vercel AI SDK streaming responses with Canvas integration
- `src/components/canvas-panel.tsx` - **Canvas workspace** - Multi-grid dashboard with progressive chart building

### Integration Files
- `src/lib/ai/mcp/mcp-manager.ts` - **MCP â†’ Vercel AI SDK conversion** - Converts MCP tools to SDK tools
- `src/app/api/chat/shared.chat.ts` - **Tool loading pipeline** - Loads all tools as Vercel AI SDK tools
- `src/lib/ai/workflow/` - **Workflow â†’ Vercel AI SDK integration** - Converts workflows to SDK tools
- `src/lib/ai/tools/chart-tool.ts` - **Chart creation tool** - Native AI SDK streaming patterns for Canvas
- `src/components/message-parts.tsx` - **Message rendering** - Handles Canvas integration with "Open Canvas" buttons

### Configuration Files
- `src/lib/db/pg/schema.pg.ts` - Database schema
- `drizzle.config.ts` - Database configuration
- `next.config.ts` - Next.js configuration (includes instrumentation hook)
- `biome.json` - Code formatting rules

## ðŸŽ¯ Development Workflows

### Adding a New Feature
1. Update database schema if needed
2. Generate migrations: `pnpm db:generate`
3. Create API routes in `src/app/api/`
4. Build UI components in `src/components/`
5. Add types to `app-types/`
6. Write tests alongside code
7. Run quality checks: `pnpm check`

### Adding Canvas Functionality
1. Create chart tools in `src/lib/ai/tools/` using native AI SDK streaming patterns
2. Use `async function*` with `yield` statements for progressive building
3. Add chart components to `src/components/tool-invocation/` with Canvas optimization
4. Ensure proper Canvas integration with `useCanvas` hook in chat interface
5. Test Chart tool execution and Canvas display functionality
6. Verify responsive scaling and multi-grid layout behavior

### Working with MCP
1. Test MCP servers in `/mcp` page
2. Configure server settings and tool customizations
3. Test tools in `/mcp/test/[id]` page
4. Tools automatically available in chat sessions

### Working with Canvas
1. AI automatically opens Canvas when creating charts using `create_chart` tool
2. Charts appear progressively as AI streams tool execution with `yield` statements
3. Canvas uses responsive CSS Grid layout (2x2, scales based on chart count)
4. Charts scale smoothly when Canvas panel is resized
5. Canvas names generated automatically based on chart content analysis
6. Use ResizablePanelGroup to adjust Canvas/chat proportions

### Debugging Performance
1. Check database queries in Studio
2. Monitor API response times via Langfuse dashboard
3. Use React DevTools for component performance
4. Check MCP server connection health
5. Monitor Vercel AI SDK streaming performance in Langfuse traces
6. Check `/api/health/langfuse` for observability system status
7. Monitor Canvas rendering performance for large datasets
8. Check chart tool streaming patterns in browser DevTools console

## ðŸ”§ Langfuse + Vercel AI SDK Troubleshooting

### Common Observability Issues
- **Missing Traces**: Check Langfuse credentials in `.env` and verify instrumentation.ts loading
- **Incomplete Traces**: Ensure `experimental_telemetry` is enabled in all `streamText` calls
- **Tool Calls Not Traced**: Verify tools are properly converted to Vercel AI SDK interface
- **Streaming Issues**: Check `observe` wrapper with `endOnExit: false` for streaming routes

### Debugging Commands
```bash
# Check Langfuse connectivity
curl http://localhost:3000/api/health/langfuse

# Enable debug logging
export NODE_ENV=development

# Check server logs for instrumentation
pnpm dev  # Look for "âœ… Langfuse instrumentation setup complete!"

# Verify trace export
# Look for "ðŸ” Span filter: ai -> EXPORT" in server logs
```

### Version Compatibility
- **Critical**: Use `NodeTracerProvider` not `@vercel/otel` due to OpenTelemetry JS SDK v2 compatibility
- **Packages**: Ensure `@langfuse/otel`, `@langfuse/tracing`, `@opentelemetry/sdk-trace-node`
- **Next.js**: Instrumentation hook automatically enabled in Next.js 15+

### Production Deployment
- **Environment Variables**: Ensure Langfuse credentials are set in production
- **Health Monitoring**: Use `/api/health/langfuse` endpoint for uptime monitoring
- **Cost Management**: Monitor token usage and costs in Langfuse dashboard
- **Performance**: Track response latencies and optimization opportunities